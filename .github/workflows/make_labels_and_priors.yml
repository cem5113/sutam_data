name: Make Labels + Train (SUTAM)

on:
  workflow_dispatch:
    inputs:
      persist:
        description: "Çıktılar nasıl saklansın?"
        type: choice
        options: [artifact, commit, none]
        default: artifact
      windows:
        description: "Multi-window frekansları (virgülle): 1D,1W,1M"
        default: "1D,1W,1M"
      horizon:
        description: "Forecast ufku (örn: 30d, 90d, 6m)"
        default: "30d"
      topk:
        description: "Şehir geneli Top-K GEOID"
        default: "50"
      stacking:
        description: "Stacking ile model eğit (XGB+LGBM+RF+LR → LR meta)"
        type: choice
        options: [no, yes]
        default: no

permissions:
  contents: write
  actions: read

jobs:
  build_and_train:
    runs-on: ubuntu-latest
    env:
      TZ: "America/Los_Angeles"
      PYTHONUTF8: "1"
      DATA_DIR: .
      OUT_FILE: sf_crime_grid_full_labeled.parquet
      OUT_ZIP:  fr-crime-outputs-parquet.zip

    steps:
      - name: Checkout repo (with LFS)
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Show workspace
        shell: bash
        run: |
          set -euo pipefail
          echo "PWD=$(pwd)"
          ls -lah

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt

      - name: Install dependencies (pinned)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install -U pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install \
              "pandas>=2.2.2,<2.3" \
              "pyarrow>=15,<19" \
              "numpy>=1.26,<2.0" \
              "scipy>=1.11,<1.13" \
              "scikit-learn>=1.4,<1.6" \
              "xgboost>=2.0,<2.1" \
              "lightgbm>=4.3,<5" \
              "imbalanced-learn>=0.12,<0.13" \
              joblib matplotlib tqdm
          fi
          python - <<'PY'
          import sys, pandas, sklearn
          print("VERSIONS:",
                "py", sys.version.split()[0],
                "pandas", pandas.__version__,
                "sklearn", sklearn.__version__)
          try:
            import xgboost, lightgbm
            print("xgb", xgboost.__version__, "lgbm", lightgbm.__version__)
          except Exception as e:
            print("xgb/lgbm info:", e)
          PY

      - name: Detect input parquet & optional files
        id: detect
        shell: bash
        run: |
          set -euo pipefail
          prefer_09="$(/usr/bin/find "${DATA_DIR}" -maxdepth 2 -type f -name 'fr_crime_09.parquet' -print -quit || true)"
          prefer_10="$(/usr/bin/find "${DATA_DIR}" -maxdepth 2 -type f -name 'fr_crime_10.parquet' -print -quit || true)"
          if [ -n "${prefer_09}" ]; then
            INPUT="${prefer_09}"
          elif [ -n "${prefer_10}" ]; then
            INPUT="${prefer_10}"
          else
            echo "❌ fr_crime_09.parquet ya da fr_crime_10.parquet bulunamadı."; exit 1
          fi
          echo "input=${INPUT}" >> "$GITHUB_OUTPUT"
          echo "✅ INPUT=${INPUT}"

          RH="$(/usr/bin/find "${DATA_DIR}" -maxdepth 2 -type f \( -name 'risk_hourly.parquet' -o -name 'risky_hours.parquet' \) -print -quit || true)"
          MET="$(/usr/bin/find "${DATA_DIR}" -maxdepth 2 -type f -name 'metrics_stacking_ohe.parquet' -print -quit || true)"
          [ -n "${RH}" ] && echo "risky_hours=${RH}" >> "$GITHUB_OUTPUT"
          [ -n "${MET}" ] && echo "metrics=${MET}"     >> "$GITHUB_OUTPUT"

      - name: Build labels + priors (+ package)
        shell: bash
        run: |
          set -euo pipefail
          INPUT="${{ steps.detect.outputs.input }}"
          OUT_PQ="${DATA_DIR}/${OUT_FILE}"
          OUT_ZIP="${DATA_DIR}/${OUT_ZIP}"

          EXTRA_ARGS=()
          [ -n "${{ steps.detect.outputs.risky_hours }}" ] && EXTRA_ARGS+=( --risky-hours "${{ steps.detect.outputs.risky_hours }}" )
          [ -n "${{ steps.detect.outputs.metrics }}" ]     && EXTRA_ARGS+=( --metrics     "${{ steps.detect.outputs.metrics }}" )

          echo "▶️  make_labels_and_priors_xl.py"
          python -u make_labels_and_priors_xl.py \
            --input       "${INPUT}" \
            --out         "${OUT_PQ}" \
            --tz          America/Los_Angeles \
            --out-dir     "${DATA_DIR}" \
            --package-zip "${OUT_ZIP}" \
            "${EXTRA_ARGS[@]}"

          test -s "${OUT_PQ}" || { echo "❌ Output parquet yok: ${OUT_PQ}"; exit 1; }
          [ -f "${DATA_DIR}/y_label_stats.csv" ] && { echo "Y_label stats:"; cat "${DATA_DIR}/y_label_stats.csv" || true; }

      - name: Aggregate multi-windows (1D tabanlı)
        shell: bash
        run: |
          set -euo pipefail
          echo "▶️  aggregate_all.py (${{ github.event.inputs.windows }})"

          RAW="${{ github.event.inputs.windows }}"
          RAW="${RAW// /}"
          ALLOWED=("1D" "1W" "1M")     # 3H/8H kesinlikle yok
          SEL=()
          IFS=',' read -r -a PARTS <<< "$RAW"
          for w in "${PARTS[@]}"; do
            for ok in "${ALLOWED[@]}"; do
              [[ "$w" == "$ok" ]] && SEL+=("$w")
            done
          done
          [[ ${#SEL[@]} -eq 0 ]] && SEL=("1D")
          FREQS="$(IFS=,; echo "${SEL[*]}")"
          echo "→ Kullanılacak frekanslar: ${FREQS}"

          python -u aggregate_all.py \
            --input "${{ env.DATA_DIR }}/${{ env.OUT_FILE }}" \
            --freqs "${FREQS}"

          ls -lh sf_crime_grid_*.parquet || true

      - name: Train models (multi-windows; stacking opsiyonel)
        shell: bash
        run: |
          set -euo pipefail
          RAW="${{ github.event.inputs.windows }}"
          RAW="${RAW// /}"
          ALLOWED=("1D" "1W" "1M")
          SEL=()
          IFS=',' read -r -a PARTS <<< "$RAW"
          for w in "${PARTS[@]}"; do
            for ok in "${ALLOWED[@]}"; do
              [[ "$w" == "$ok" ]] && SEL+=("$w")
            done
          done
          [[ ${#SEL[@]} -eq 0 ]] && SEL=("1D")
          FREQS="$(IFS=,; echo "${SEL[*]}")"
          echo "→ Eğitim frekansları: ${FREQS}"

          if [[ "${{ github.event.inputs.stacking }}" == "yes" && -f "train_stacking_multi_windows.py" ]]; then
            echo "▶️  train_stacking_multi_windows.py"
            python -u train_stacking_multi_windows.py --dir "." --freqs "${FREQS}"
          else
            echo "▶️  train_multi_windows.py"
            python -u train_multi_windows.py \
              --dir "." \
              --prefix "sf_crime_grid_" \
              --freqs "${FREQS}" \
              --undersample "0.0"
          fi

          ls -lh models || true
          ls -lh reports || true

      - name: Run risk_forecast (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f risk_forecast.py ]; then
            echo "▶️  risk_forecast.py (freq=1D, horizon=${{ github.event.inputs.horizon }}, topk=${{ github.event.inputs.topk }})"
            python -u risk_forecast.py \
              --freq 1D \
              --horizon "${{ github.event.inputs.horizon }}" \
              --topk "${{ github.event.inputs.topk }}"
            ls -lh forecasts || true
          else
            echo "ℹ️ risk_forecast.py bulunamadı, forecast adımı atlandı."
          fi

      - name: Upload artifacts (if selected)
        if: ${{ github.event.inputs.persist == 'artifact' }}
        uses: actions/upload-artifact@v4
        with:
          name: sutam-model-outputs
          path: |
            ${{ env.DATA_DIR }}/${{ env.OUT_FILE }}
            ${{ env.DATA_DIR }}/${{ env.OUT_ZIP }}
            ${{ env.DATA_DIR }}/y_label_stats.csv
            sf_crime_grid_*.parquet
            models/*.joblib
            reports/*.json
            reports/*.csv
            reports/*.txt
            forecasts/*.*
          if-no-files-found: warn
          retention-days: 14

      - name: Commit outputs (if selected)
        if: ${{ github.event.inputs.persist == 'commit' }}
        shell: bash
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "${DATA_DIR}/${OUT_FILE}" 2>/dev/null || true
          git add "${DATA_DIR}/${OUT_ZIP}"  2>/dev/null || true
          [ -f "${DATA_DIR}/y_label_stats.csv" ] && git add "${DATA_DIR}/y_label_stats.csv" || true
          git add sf_crime_grid_*.parquet 2>/dev/null || true
          git add models/*.joblib 2>/dev/null || true
          git add reports/* 2>/dev/null || true
          git add forecasts/* 2>/dev/null || true
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git commit -m "chore: labels+priors, 1D/1W/1M aggregation/training & forecasts"
          git push origin "${GITHUB_REF_NAME:-$(git rev-parse --abbrev-ref HEAD)}"

      - name: Job summary
        shell: bash
        run: |
          set -e
          {
            echo "## Make Labels + Train — Özet"
            echo "- Input: \`${{ steps.detect.outputs.input }}\`"
            echo "- Windows (raw): \`${{ github.event.inputs.windows }}\`"
            echo "- Stacking: \`${{ github.event.inputs.stacking }}\`"
            echo "- Forecast: horizon=\`${{ github.event.inputs.horizon }}\`, topk=\`${{ github.event.inputs.topk }}\`"
            [ -n "${{ steps.detect.outputs.risky_hours }}" ] && echo "- risky_hours: \`${{ steps.detect.outputs.risky_hours }}\`"
            [ -n "${{ steps.detect.outputs.metrics }}" ] && echo "- metrics: \`${{ steps.detect.outputs.metrics }}\`"
            echo "- Output Parquet: \`${{ env.DATA_DIR }}/${{ env.OUT_FILE }}\`"
            echo "- Output ZIP: \`${{ env.DATA_DIR }}/${{ env.OUT_ZIP }}\`"
            [ -f "${{ env.DATA_DIR }}/y_label_stats.csv" ] && { echo ""; echo "### Y_label dağılımı"; tail -n +1 "${{ env.DATA_DIR }}/y_label_stats.csv"; }
            echo ""; ls -lh models 2>/dev/null || true
            echo ""; ls -lh reports 2>/dev/null || true
            echo ""; ls -lh forecasts 2>/dev/null || true
          } >> "$GITHUB_STEP_SUMMARY"
